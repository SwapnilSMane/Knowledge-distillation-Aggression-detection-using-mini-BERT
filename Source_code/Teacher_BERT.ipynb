{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b6f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 18:52:06.418722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-01 18:52:06.418755: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70e9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('preprocessed_data/train.pkl')\n",
    "val = pd.read_pickle('preprocessed_data/val.pkl')\n",
    "test = pd.read_pickle('preprocessed_data/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafaa60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train.label)\n",
    "\n",
    "train['label'] = le.transform(train['label'])\n",
    "val['label'] = le.transform(val['label'])\n",
    "test['label'] = le.transform(test['label'])\n",
    "df_train = train\n",
    "df_val = val\n",
    "df_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e33d85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby(['label']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db9d35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fbe045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554a56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = list(df['label'])\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['sentence']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db3bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbda1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b56553",
   "metadata": {},
   "outputs": [],
   "source": [
    " def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5791e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11999 3001 916\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a5e5bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [28:58<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.324 | Train Accuracy:  0.607 | Val Loss:  0.304 | Val Accuracy:  0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [42:02<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.272 | Train Accuracy:  0.733 | Val Loss:  0.275 | Val Accuracy:  0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [14:08<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.230 | Train Accuracy:  0.799 | Val Loss:  0.277 | Val Accuracy:  0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [29:03<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.174 | Train Accuracy:  0.866 | Val Loss:  0.302 | Val Accuracy:  0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6000/6000 [32:48<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.114 | Train Accuracy:  0.930 | Val Loss:  0.346 | Val Accuracy:  0.707\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7c8e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'agg_teacher_model_method2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b36439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d2a4bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.636\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa28a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
